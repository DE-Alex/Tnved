**По-русски** | [In english](docs_eng/README.md)
#### EtL-проект по извлечению данных из справочника ТН ВЭД на сайте ФНС
#### О проекте
Учебный EtL-проект по извлечению данных из справочника "Товарная номенклатура внешнеэкономической деятельности" (ТНВЭД), их нормализации и загрузке в базу данных.
Источник данных: справочник ТН ВЭД размещённый на сайте Федеральной налоговой службы (https://www.nalog.gov.ru/rn77/program/5961290/).
Проект выполнен в виде отдельных скриптов и позволяет автоматизировать из запуск с помощью Apache Airflow или планировщика.
#### ПО и IT-технологии используемые в проекте:
* OS: Windows 10 / Linux (Ubuntu 22.04)
* Язык программирования: Python 3.10
* Язык запросов: SQL
* СУБД: PostgreSQL 14.9
#### Схема EtL процесса
![EtL_scheme](https://github.com/DE-Alex/EtL_jobs/assets/139635578/6ad1f7af-1b75-499b-a3ec-31fb93b926d6)
---
#### Подробное описание 
В проекте использовались стандартные модули Python, а также модули:
- requests (загрузка данных с сайта)
- python-dateutil (работа с датами)
- psycopg (подключение и работа с Postgres)
Для настройки окружения можно использовать [requirements.txt](requirements.txt)
формате реляционной базы данных учитывающая срок действия кодов, отношение родитель у кода и описание кодов

#### Возможное развитие
1. Портировать скрипты для HeadHunter на Linux. Сделать DAG. Срок: 07.10.23.
2. Мигрировать собранные на НН данные из SQLight в PostgreSQL. Срок: 10.10.23.
3. Зарегистрироваться на Yandex DataLens. Сделать скрипт по загрузке данных в облако. Срок: 15.10.23.
4. Сделать диаграммы с ключевыми метриками собранных данных. Срок: 20.10.23.
5. Сделать диаграмму с демонстрацией образцов собранных данных. Срок: 20.10.23.
6. Сделать диаграмму с ключевыми метриками EtLT процесса на основе данных AirFlow. Срок: 25.10.23.
7. Сделать скрипт резервного копирования данных. Срок: 31.10.23.
